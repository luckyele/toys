	
搜索引擎的基本工作原理
https://blog.csdn.net/u013521220/article/details/62043490

搜索引擎的原理，可以分为四步：从互联网上抓取网页、建立索引数据库、在索引数据库中搜索排序、对搜索结果进行处理和排序。


https://baike.baidu.com/item/%E5%9E%82%E7%9B%B4%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E/210198

垂直搜索的难点不是技术，而是用户参与门户网站行为的创新和垂直门户网站对产业上下游信息资源的整合。
垂直搜索引擎的目标是帮助用户解决问题，而不只是像通用搜索引擎一样发现信息：这一点是垂直搜索引擎的终极目标。在做垂直搜索引擎的时候你需要考虑：什么问题是这个行业内的特殊性问题，什么问题是一般性问题。keso多次提到google的目标是让用户尽快离开google，而垂直搜索引擎应该粘住用户。一般来说，使用垂直搜索引擎的用户都是和用户的利益需求密切相关的。所谓利益需求是我自己独创的，大意是和用户工作密切相关，生活中必不可少的需求，而求有持续性。比如：学生找论文，业主找装修信息等等这样的需求。因此粘住用户，让用户有反馈的途径是一个关键部分。
8、垂直搜索引擎的社区化特征：这一条和第7条是相关的。俗话说物以类聚，人以群分，垂直搜索引擎定位于一个行业，服务于一群特定需求的人群，这个特点决定了垂直搜索的社区化行为。人们利用垂直搜索引擎解决问题，分享回馈。做网站都讲求社区化，所以垂直搜索引擎本质上还是：对垂直门户信息提供方式的一次简化性的整合。
垂直搜索引擎和普通的网页搜索引擎的最大区别是对网页信息进行了结构化信息抽取，也就是将网页的非结构化数据抽取成特定的结构化信息数据，好比网页搜索是以网页为最小单位，基于视觉的网页块分析是以网页块为最小单位，而垂直搜索是以结构化数据为最小单位。然后将这些数据存储到数据库，进行进一步的加工处理，如：去重、分类等，最后分词、索引再以搜索的方式满足用户的需求。整个过程中，数据由非结构化数据抽取成结构化数据，经过深度加工处理后以非结构化的方式和结构化的方式返回给用户。



[硕士论文] 垂直搜索引擎的设计与实现
https://wenku.baidu.com/view/064b08d5360cba1aa811da3e.html


垂直搜索引擎模块设计
https://blog.csdn.net/ranxs/article/details/6886154

1：配置模块：
采集目标：新闻，用户评论,博客，论坛等等
采集源配置的集成开发环境，可视化。

2：爬虫模块：
网站内容组织结构（网站地图）的自动识别。
支持cookie二次验证(如新华网)，验证码登陆的支持编辑弹出验证

3：初次过滤模块（过滤广告，导航等无用信息）
概览页面选定区域内包含链接的规则识别、地址过滤和转换。
细览页面选定区域内包含数据的精确识别、格式转换（内码转换，地址转换，时间转换等等）
基于视觉的网页自动分区技术（VIPS），网页分区后的区域类型和特征的自动标注。
DOM树结构分析；基于分区的网页结构分析思想，可视化的区域选择配置

4：任务调度模块：更新策略，调度策略，日志管理
预设监控目标网站的各项阈值，提供异常情况发生的报警机制；考虑URL二级映射，以便爬虫服务器在动态增减后数据交换量尽量少

5：数据挖掘模块：
文本分类、文本聚类、相似性检索、自动摘要、自动分词、信息抽取、敏感信息过滤、情感分析、拼音检索、相关短语检索
5.1文本分类：
基于统计的文本分类（训练语料库，支持修改补充语料库和规则库）；支持多级和复分；支持基于语义分析的向量空间模型，用户可以建立知识词典，模块自动调用知识库资源，进一步提高分类的精确度。
基于规则体系的文本分类（编写分类规则）:
规则支持“与或非”等逻辑运算和词频数条件设置。
比如表达式：作者=（刘翔+顾宝刚）- 正文=（比赛）；标题=（复出） + 正文=（美国+治疗）
K近邻法和支持向量机等分类算法：http://www.360doc.com/content/070716/23/11966_615236.html

某SVM分类器：http://www.csie.ntu.edu.tw/~cjlin/libsvm/

5.2文本聚类：
将相近、相似或者相同特征的文本聚合在一起

5.3相似性检索
用户可以自定义相似度阈值
提取网页摘要、关键词和主题词等特征，自动生成唯一序列，自动判断信息指纹是否相等
效率方面用倒排索引机制等等提高

5.4自动摘要
用户可以建立专业词典，自定义线索词
网页包含关键词的自动提取

5.5自动分词
第一阶段：正向减字最大匹配+逆向减字最大匹配，如果不相同，再用回溯法重新处理
第二阶段：
规则与统计相结合，内嵌分词歧义规则库
提供词性标注功能，准确识别人名、地名、组织机构名等信息
分词词典：系统支持设立主题词表、同义词/反义词典、禁用词典以及词典按需 维护
分词规则库：统计建立了大量歧义排除规则，有效提高了分词准确性、提高了 查准率。
支持主题词典自动扩展检索、同义词/反义词自动扩展检索、全半角 自动扩展检索、简繁体自动扩展检索（基于权威知识库体系，辅助元数据信息的纠错和补全）

5.6信息抽取
抽取目标：结构化（时间），半结构化（html），非结构化（人名、地名、机构名、时间以及货币等等）

抽取方法：
1：模板技术（人工标注各类模板库，然后自动萃取。有可能的话用神经网络自动训练）
2：启发式的获取（新闻的正文一般在标题下面最近的一块大区域）
3：利用视觉相似性自动分析网页语义结构（目前比较流行的方式）

对于js信息（js解释器本地解析或者模拟触发js事件，如搜狐论坛）

5.7情感分析

 

6存储模块：
结构化数据：各种关系数据库
非机构化数据：文件系统Lucene做索引，BigTable（HBase、Hypertable）
分布式：Hadoop集群，MogileFS自动备份等等

